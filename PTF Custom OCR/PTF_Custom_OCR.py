# -*- coding: utf-8 -*-
"""DOLPHIN OCR TASK.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1At-6OFX1sZO3BgUUD9WJYw9BSHAWG0Py
"""

# # 1. Install necessary libraries
# !pip install -U transformers
# !pip install -q pdf2image Pillow
# !apt-get update
# !apt-get install -y poppler-utils

# # Commented out IPython magic to ensure Python compatibility.
# # 2. Clone the ByteDance Dolphin repository
# !git clone https://github.com/ByteDance/Dolphin.git
# # %cd Dolphin
# !git lfs install
# !git clone https://huggingface.co/ByteDance/Dolphin ./hf_model
# # %cd ..

# !pip install pymupdf

# !pip install gradio

# # Commented out IPython magic to ensure Python compatibility.
# # Run these in your Colab or terminal before using the app
# !git clone https://github.com/datalab-to/surya
# # %cd surya
# !pip install -e .
# # %cd ..

# !pip install --upgrade --force-reinstall torch torchvision --index-url https://download.pytorch.org/whl/cu118

# !pip install pymupdf

# Modified: Output will be in structured JSON instead of Markdown
import gradio as gr
import os
import fitz  # PyMuPDF
import json
import uuid
import tempfile
from PIL import Image
from pdf2image import convert_from_bytes
import subprocess
from surya.recognition import RecognitionPredictor
from surya.detection import DetectionPredictor
import shutil
import base64
from io import BytesIO

# Dolphin settings
DOLPHIN_MODEL_PATH = "Dolphin/hf_model"
DOLPHIN_SCRIPT = "Dolphin/demo_page_hf.py"

def run_dolphin_layout_on_pdf(pdf_bytes: bytes):
    session_id = str(uuid.uuid4())
    work_dir = tempfile.mkdtemp(prefix=f"dolphin_session_{session_id}_")
    pdf_path = os.path.join(work_dir, "input.pdf")

    with open(pdf_path, "wb") as f:
        f.write(pdf_bytes)

    images = convert_from_bytes(pdf_bytes, dpi=300)
    images_dir = os.path.join(work_dir, "pdf_images")
    os.makedirs(images_dir, exist_ok=True)
    for i, img in enumerate(images):
        img.save(os.path.join(images_dir, f"page_{i+1}.png"))

    dolphin_results_dir = os.path.join(work_dir, "dolphin_structured_results")
    os.makedirs(dolphin_results_dir, exist_ok=True)
    result = subprocess.run([
        "python3", DOLPHIN_SCRIPT,
        "--model_path", DOLPHIN_MODEL_PATH,
        "--input_path", images_dir,
        "--save_dir", dolphin_results_dir
    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    if result.returncode != 0:
        raise RuntimeError(f"Dolphin failed:\n{result.stderr.decode()}")

    return pdf_path, os.path.join(dolphin_results_dir, "recognition_json"), work_dir

def extract_layout_images(pdf_path, json_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    doc = fitz.open(pdf_path)

    for page_index in range(len(doc)):
        page = doc[page_index]
        pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72))
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        json_path = os.path.join(json_dir, f"page_{page_index+1}.json")
        if not os.path.exists(json_path):
            continue

        with open(json_path, "r", encoding="utf-8") as f:
            bboxes = json.load(f)

        for i, item in enumerate(bboxes):
            label = item.get("label", "other")
            bbox = item["bbox"]
            cropped = img.crop(bbox)
            label_dir = os.path.join(output_dir, label)
            os.makedirs(label_dir, exist_ok=True)
            filename = f"page{page_index+1}_{label}_{i+1}.png"
            cropped.save(os.path.join(label_dir, filename))

    doc.close()
    return output_dir

def reorder_crops_as_pdf(pdf_path, json_dir, crops_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    doc = fitz.open(pdf_path)
    block_index = 1

    for page_num in range(len(doc)):
        json_path = os.path.join(json_dir, f"page_{page_num+1}.json")
        if not os.path.exists(json_path):
            continue

        with open(json_path, "r", encoding="utf-8") as f:
            bboxes = json.load(f)

        for i, block in enumerate(bboxes):
            label = block.get("label", "other")
            crop_path = os.path.join(crops_dir, label, f"page{page_num+1}_{label}_{i+1}.png")
            if not os.path.exists(crop_path):
                continue

            new_name = f"{block_index:04d}_{label}.png"
            new_path = os.path.join(output_dir, new_name)
            Image.open(crop_path).save(new_path)
            block_index += 1

    doc.close()
    return output_dir

def run_dolphin_on_image_dir(image_dir, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    result = subprocess.run([
        "python3", DOLPHIN_SCRIPT,
        "--model_path", DOLPHIN_MODEL_PATH,
        "--input_path", image_dir,
        "--save_dir", save_dir
    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        raise RuntimeError(f"Dolphin failed:\n{result.stderr.decode()}")

# Initialize Surya OCR models
detector = DetectionPredictor()
recognizer = RecognitionPredictor()

def process_pdf_for_ocr(pdf_bytes):
    work_dir = None
    try:
        pdf_path, json_dir, work_dir = run_dolphin_layout_on_pdf(pdf_bytes)

        crops_dir = os.path.join(work_dir, "layout_crops")
        extract_layout_images(pdf_path, json_dir, crops_dir)

        ordered_dir = os.path.join(work_dir, "ordered_blocks")
        reorder_crops_as_pdf(pdf_path, json_dir, crops_dir, ordered_dir)

        ordered_dolphin_results_dir = os.path.join(work_dir, "ordered_dolphin_structured_results")
        run_dolphin_on_image_dir(ordered_dir, ordered_dolphin_results_dir)
        ordered_dolphin_json_dir = os.path.join(ordered_dolphin_results_dir, "recognition_json")

        output_json_path = os.path.join(work_dir, "hybrid_output.json")
        output_data = {"blocks": []}

        image_files = sorted([
            f for f in os.listdir(ordered_dir)
            if f.lower().endswith((".png", ".jpg", ".jpeg", ".webp"))
        ])

        for filename in image_files:
            image_path = os.path.join(ordered_dir, filename)
            base_name = os.path.splitext(filename)[0]
            parts = base_name.split("_")
            inferred_type = parts[1].lower() if len(parts) >= 2 else "unknown"

            inferred_type_map = {
                "tab": "table", "fig": "figure", "img": "figure",
                "para": "paragraph", "sec": "section", "list": "list"
            }
            inferred_type = inferred_type_map.get(inferred_type, inferred_type)

            image = Image.open(image_path).convert("RGB")
            block = {"type": inferred_type}

            try:
                if inferred_type == "figure":
                    buffered = BytesIO()
                    image.save(buffered, format="PNG")
                    img_str = base64.b64encode(buffered.getvalue()).decode()
                    block["image_base64"] = img_str

                elif inferred_type == "table":
                    json_path = os.path.join(ordered_dolphin_json_dir, f"{base_name}.json")
                    if os.path.exists(json_path):
                        with open(json_path, "r", encoding="utf-8") as jf:
                            obj = json.load(jf)
                        table_data = [line["text"].strip().split(",") for line in obj if line.get("text")]
                        block["data"] = table_data
                    else:
                        block["error"] = "Dolphin table result not found."

                else:
                    results = recognizer([image], det_predictor=detector)
                    result = results[0]
                    text_lines = [line.text.strip() for line in result.text_lines if line.text.strip()]
                    block["text"] = "\n".join(text_lines) if text_lines else "No text found."

            except Exception as e:
                block["error"] = str(e)

            output_data["blocks"].append(block)

        with open(output_json_path, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        return output_json_path
    finally:
        pass

# Gradio Interface
iface = gr.Interface(
    fn=process_pdf_for_ocr,
    inputs=gr.File(label="Upload PDF", type="binary"),
    outputs=gr.File(label="Download JSON"),
    title="PDF OCR with Dolphin and Surya",
    description="Upload a PDF to detect layout using Dolphin and perform OCR using Surya. The result is returned as a structured JSON file."
)

iface.launch(share=True)